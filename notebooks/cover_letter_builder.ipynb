{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4fdab5",
   "metadata": {},
   "source": [
    "# Cover Letter Generator\n",
    "In this notebook we are going to create a Cover letter generator RAG using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcfa90",
   "metadata": {},
   "source": [
    "## Workflow of Cover Letter Generator\n",
    "1. Input Collection\n",
    "* User uploads Resume (PDF/DOCX → parsed into text).\n",
    "* User pastes Job Description (JD).\n",
    "\n",
    "2. Keyword Extraction (LangChain pipeline #1)\n",
    "* Use an LLM + PydanticOutputParser to extract:\n",
    "    - role (e.g., \"Data Scientist\")\n",
    "    - seniority (e.g., \"Mid-level\")\n",
    "    - must_have (e.g., Python, SQL, Machine Learning)\n",
    "    - nice_to_have (e.g., Cloud, Docker, NLP)\n",
    "    - tools (e.g., TensorFlow, PyTorch, Tableau)\n",
    "✅ Output = structured JDKeywords object.\n",
    "\n",
    "3. Resume Analysis\n",
    "\n",
    "* Parse the resume into sections: Experience, Skills, Projects, Education.\n",
    "* Extract skills & experiences → again with a structured schema (e.g., ResumeProfile).\n",
    "\n",
    "4. Keyword Matching\n",
    "\n",
    "* Compare JD keywords vs Resume keywords.\n",
    "* Mark:\n",
    "    - ✅ Matches (strengths to emphasize).\n",
    "    - ❌ Gaps (skills missing → handled carefully, not overclaimed).\n",
    "\n",
    "5. Cover Letter Generation (LangChain pipeline #2)\n",
    "\n",
    "* Prompt template uses:\n",
    "    - JDKeywords (so letter aligns with employer’s needs).\n",
    "    - ResumeProfile (so letter emphasizes relevant experience).\n",
    "    - LLM writes a personalized cover letter, structured into:\n",
    "    - Greeting\n",
    "    - Hook (why the candidate is interested in this role/company)\n",
    "    - Body (match candidate’s experience → JD requirements)\n",
    "    - Closing (enthusiasm + call to action)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec55c5",
   "metadata": {},
   "source": [
    "configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b97f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "class Settings:\n",
    "    def __init__(self) -> None:\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        self.gemini_api = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        self.tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        \n",
    "    def load_gemini(self, temp: float = 0.5) -> ChatGoogleGenerativeAI:\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model = \"gemini-1.5-flash\",\n",
    "            api_key = self.gemini_api,\n",
    "            temperature = temp\n",
    "        )\n",
    "        print(\"LLM ready:\", type(llm).__name__)\n",
    "        return llm\n",
    "    def load_gemma(self, temp: float = 0.5)->ChatOpenAI:\n",
    "        \"\"\"\n",
    "        This method returns the local gemma3 model hosted by LM Studio.\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"google/gemma-3-4b\",\n",
    "            openai_api_key = 'lm-studio', # type: ignore\n",
    "            openai_api_base=\"http://localhost:1234/v1\", # type: ignore\n",
    "            temperature=temp\n",
    "        )\n",
    "        return llm\n",
    "    \n",
    "    def load_tavily_search(self, max_results: int = 2) -> TavilySearchResults:\n",
    "        return TavilySearchResults(max_results = max_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85290929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready: ChatGoogleGenerativeAI\n"
     ]
    }
   ],
   "source": [
    "config = Settings()\n",
    "llm = config.load_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498258a",
   "metadata": {},
   "source": [
    "## Define the schemas\n",
    "We will use this schemas to structure our outputs from LLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75277070",
   "metadata": {},
   "source": [
    "1. schema for extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45544a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class JDKeyWords(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"Role inferred from job description\")\n",
    "    seniority: Optional[str] = Field(None, description=\"Seniority level like junior, senior, associate etc\")\n",
    "    must_have: List[str] = Field(..., description=\"Critical must-have skills needed for the job\")\n",
    "    nice_to_have: List[str] = Field(default_factory=list, description=\"Optional skills\")\n",
    "    tools: List[str] = Field(default_factory=list, description=\"Software/tools needed for this job\")\n",
    "\n",
    "# ... means the field is required\n",
    "# Optional[str] means it can be a string or None\n",
    "# if tools is empty then we will return a []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "873bb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover_letter schema\n",
    "class CoverLetterOut(BaseModel):\n",
    "    cover_letter: str = Field(... , description=\"Generated cover letter text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fa3b4",
   "metadata": {},
   "source": [
    "## Creating Pipelines\n",
    "\n",
    "* pipeline to extract keywords from job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ae1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=JDKeyWords)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI tool that is responsible for extracting hiring signals from job description.\"\n",
    "     \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "     (\"human\",\n",
    "      \"Job description:\\n {job_description}\\n\"\n",
    "      \"Be precise. Keep lists concise and deduplicated\")\n",
    "]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "jd = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c75e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc = \"\"\"\n",
    "Job Description: Senior Full-Stack Developer\n",
    "Company: InnovateTech Solutions\n",
    "Location: San Francisco, CA (Hybrid Remote)\n",
    "Job Type: Full-Time\n",
    "\n",
    "About Us\n",
    "At InnovateTech Solutions, we're building the next generation of SaaS tools that empower businesses to thrive. Our platform leverages cutting-edge AI and data analytics to provide actionable insights. Join our passionate team of engineers and play a key role in shaping our product's future.\n",
    "\n",
    "The Role\n",
    "We are seeking a highly skilled and motivated Senior Full-Stack Developer to design, develop, and implement robust software solutions. You will be involved in all stages of the product lifecycle, from concept to deployment, and will mentor junior developers on the team. This is a fantastic opportunity to make a significant impact on a product used by thousands.\n",
    "\n",
    "Key Responsibilities\n",
    "Design, code, test, and manage full-stack applications from the database to the UI.\n",
    "\n",
    "Collaborate with product managers, designers, and other engineers to define, design, and ship new features.\n",
    "\n",
    "Lead technical architecture discussions and make recommendations on system improvements.\n",
    "\n",
    "Write clean, maintainable, and efficient code while following best practices.\n",
    "\n",
    "Conduct code reviews and provide constructive feedback to team members.\n",
    "\n",
    "Identify and troubleshoot complex performance and scalability issues.\n",
    "\n",
    "Must-Have Qualifications\n",
    "5+ years of professional experience in software development.\n",
    "\n",
    "Frontend: Proven expertise with modern JavaScript frameworks, specifically React and its ecosystem (Redux, Webpack, Hooks).\n",
    "\n",
    "Backend: Strong proficiency in Python and experience with web frameworks, specifically Django or FastAPI.\n",
    "\n",
    "Database: Experience with both PostgreSQL and Redis.\n",
    "\n",
    "Cloud & DevOps: Hands-on experience with AWS (EC2, S3, RDS, Lambda) and familiarity with Docker and CI/CD pipelines.\n",
    "\n",
    "Solid understanding of RESTful API design principles.\n",
    "\n",
    "Experience with version control using Git.\n",
    "\n",
    "Nice-to-Have Qualifications\n",
    "Experience with TypeScript.\n",
    "\n",
    "Knowledge of GraphQL.\n",
    "\n",
    "Familiarity with testing frameworks (e.g., Jest, Pytest, Cypress).\n",
    "\n",
    "Understanding of agile/scrum development methodologies.\n",
    "\n",
    "Previous experience in a startup or SaaS environment.\n",
    "\n",
    "Experience with Kubernetes.\n",
    "\n",
    "Tools You'll Use\n",
    "Frontend: React, Redux Toolkit, TypeScript, Vite, Jest\n",
    "\n",
    "Backend: Python, Django REST Framework, FastAPI, Celery\n",
    "\n",
    "Database: PostgreSQL, Redis\n",
    "\n",
    "Infrastructure: AWS, Docker, GitHub Actions, Terraform\n",
    "\n",
    "Collaboration: Jira, Slack, Figma, Confluence\n",
    "\n",
    "What We Offer\n",
    "Competitive salary and equity package.\n",
    "\n",
    "Comprehensive health, dental, and vision insurance.\n",
    "\n",
    "401(k) with company matching.\n",
    "\n",
    "Flexible work schedule and generous PTO.\n",
    "\n",
    "Professional development budget.\n",
    "\n",
    "A collaborative, inclusive, and innovative culture.\n",
    "\n",
    "How to Apply\n",
    "\n",
    "If you are excited about this opportunity, please apply with your resume and a link to your GitHub profile or portfolio.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af12ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jd_keywords(job_desc: str, llm)->JDKeyWords:\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=JDKeyWords)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI tool that is responsible for extracting hiring signals from job description.\"\n",
    "     \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "     (\"human\",\n",
    "      \"Job description:\\n {job_description}\\n\"\n",
    "      \"Be precise. Keep lists concise and deduplicated\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    jd = prompt | llm | parser\n",
    "    result = jd.invoke({\"job_description\": job_desc})\n",
    "    \n",
    "    return result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa766ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"Senior Full-Stack Developer\",\n",
      "  \"seniority\": \"Senior\",\n",
      "  \"must_have\": [\n",
      "    \"5+ years of professional experience in software development\",\n",
      "    \"Proven expertise with modern JavaScript frameworks, specifically React and its ecosystem (Redux, Webpack, Hooks)\",\n",
      "    \"Strong proficiency in Python and experience with web frameworks, specifically Django or FastAPI\",\n",
      "    \"Experience with both PostgreSQL and Redis\",\n",
      "    \"Hands-on experience with AWS (EC2, S3, RDS, Lambda) and familiarity with Docker and CI/CD pipelines\",\n",
      "    \"Solid understanding of RESTful API design principles\",\n",
      "    \"Experience with version control using Git\"\n",
      "  ],\n",
      "  \"nice_to_have\": [\n",
      "    \"Experience with TypeScript\",\n",
      "    \"Knowledge of GraphQL\",\n",
      "    \"Familiarity with testing frameworks (e.g., Jest, Pytest, Cypress)\",\n",
      "    \"Understanding of agile/scrum development methodologies\",\n",
      "    \"Previous experience in a startup or SaaS environment\",\n",
      "    \"Experience with Kubernetes\"\n",
      "  ],\n",
      "  \"tools\": [\n",
      "    \"React\",\n",
      "    \"Redux Toolkit\",\n",
      "    \"TypeScript\",\n",
      "    \"Vite\",\n",
      "    \"Jest\",\n",
      "    \"Python\",\n",
      "    \"Django REST Framework\",\n",
      "    \"FastAPI\",\n",
      "    \"Celery\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Redis\",\n",
      "    \"AWS\",\n",
      "    \"Docker\",\n",
      "    \"GitHub Actions\",\n",
      "    \"Terraform\",\n",
      "    \"Jira\",\n",
      "    \"Slack\",\n",
      "    \"Figma\",\n",
      "    \"Confluence\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#llm2 = config.load_gemma()\n",
    "\n",
    "result1 = generate_jd_keywords(job_desc , llm)\n",
    "print(json.dumps(result1 , indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895f506",
   "metadata": {},
   "source": [
    "## Pipeline to extract the contents of the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0896dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeProfile(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the cantidate applying for the job\")\n",
    "    contact: List[str] = Field(default_factory=list , description=\"contact informations such as email, phone etc\")\n",
    "    education: List[str] = Field(default_factory=list, description=\"Contains the education information of the cantidate.\")\n",
    "    experience: List[str] = Field(default_factory=list ,  description=\"Work experience of the cantidate mentioned in resume, with a short description\")\n",
    "    skills: List[str] = Field(..., description=\"Skills of the cantidate mentioned in the resume.\")\n",
    "    projects: List[str] = Field(default_factory=list , description=\"Projects done by the candidate with a short description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "872849b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"resume.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "resume_text = \"\\n\".join([p.page_content for p in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d3e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeReport(BaseModel):\n",
    "    matched_skills: List[str] = Field(... , description=\"Skills that are needed in job description and present in resume\")\n",
    "    missed_skills: List[str] = Field(default_factory=list , description=\"Skills needed in job description but not present in resume.\")\n",
    "    phrasing_suggestions: List[str] = Field(\n",
    "        default_factory=list, description=\"Concrete bullet suggestions to add\"\n",
    "    )\n",
    "    relevance_score: int = Field(..., ge=0, le=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f305a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_profile(resume: str , llm)->ResumeProfile:\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeProfile)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are an AI tool that analyzes a resume in the form of string and parse information in a structured format.\"\n",
    "         \"Include a brief and small description about the experience(if any) and projects(if any) done by the user\"\n",
    "         \"Return ONLY valid JSON that matches this schema:\\n{format_instructions}\"),\n",
    "         (\"human\",\n",
    "          \"Below contains the resume:\\n\\n {resume_text}\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\"resume_text\":resume})\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56cccd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Amal Varghese\",\n",
      "  \"contact\": [\n",
      "    \"Kerala, India\",\n",
      "    \"LinkedIn\",\n",
      "    \"+919207506741\",\n",
      "    \"officialamalv2004@gmail.com\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    \"Model Engineering College, Trikkakara Kerala, India Bachelor of Technology (GPA: 9.33) September 2023 \\u2013 Present\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    \"IEDC MEC Kerala, India Tech Team Member September 2020 \\u2013 Present \\u25cf Collaborated in the development and maintenance of EventSync, a comprehensive event management platform designed to manage multiple events with over 1000 users. \\u25cf Contributed to the development of the user interface and helped scale the website's architecture.\",\n",
      "    \"CSRBOX & IBM SkillsBuild Remote Web Development Intern June 2024 - August 2024 \\u25cf Selected for and completed a competitive 6-week web development internship program. \\u25cf Developed BookBridge, a full-featured, serverless book donation platform, as the primary internship project.\",\n",
      "    \"Wrench Solutions Kochi, Kerala Machine Learning Intern May 2025 \\u2013 Present \\u25cf Developing a predictive machine learning model to forecast epileptic seizures using EEG (Electroencephalogram) data. \\u25cf Applying fractal analysis techniques to extract complex features and patterns from EEG signals for model input. \\u25cf Researching and implementing various machine learning algorithms to optimize the model's predictive accuracy and performance.\"\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"ReactJS\",\n",
      "    \"NextJS\",\n",
      "    \"React Native\",\n",
      "    \"FastAPI\",\n",
      "    \"PyTorch\",\n",
      "    \"numpy\",\n",
      "    \"matplotlib\",\n",
      "    \"Pandas\",\n",
      "    \"MySQL\",\n",
      "    \"MongoDB\",\n",
      "    \"ExpressJS\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"FoodVision May 2025 \\u25cf Developed and trained multiple Convolutional Neural Network (CNN) architectures, including TinyVGG and VGG, to classify images from the Food101 dataset, achieving nearly 80% test accuracy. \\u25cf Fine-tuned a pre-built ResNet model, significantly improving performance to 97% test accuracy.\",\n",
      "    \"Vitalia.ai November 2024 \\u2013 January 2025 , \\u25cf Collaborated in the creation of an AI-based health application that provides users with health scores and personalized diet recommendations. \\u25cf Contributed to the development of the user interface, database, and a machine learning model using XGBoost.\",\n",
      "    \"RadNexus July 2025 \\u2013 present \\u25cf Implementing a U-Net-based architecture to perform semantic segmentation on MRI images, precisely identifying and outlining specific regions of interest \\u25cf Curated and preprocessed BraTS dataset of MRI images to prepare for model training and validation.\",\n",
      "    \"CarbonTally November 2024 \\u25cf Co-developed an AI-based carbon emission tracker that generates carbon footprint details based on users' daily activities. \\u25cf Used XGBoost algorithm to develop an ML model to predict carbon emission.\",\n",
      "    \"BookBridge July \\u2013 2025 \\u25cf Developed a gamified eBook reading application using React Native, offering features such as progress tracking, badges, and interactive reading statistics. \\u25cf Integrated a fast, scalable SQL database to handle user data, reading sessions, and real-time updates.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = get_resume_profile(resume_text , llm)\n",
    "print(json.dumps(result , indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "141ab0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Johnathan Chen\",\n",
      "  \"contact\": [\n",
      "    \"San Francisco, CA\",\n",
      "    \"(555) 123-4567\",\n",
      "    \"johnathan.chen@email.com\",\n",
      "    \"linkedin.com/in/johnathanchen\",\n",
      "    \"github.com/jchen-dev\"\n",
      "  ],\n",
      "  \"education\": [\n",
      "    \"Bachelor of Science in Computer Science | University of Texas at Austin | *2014 \\u2013 2018*\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    \"Senior Software Engineer | TechNova Inc., San Francisco, CA | June 2020 \\u2013 Present\\n\\nLed the end-to-end development of a new B2B SaaS analytics dashboard using React, TypeScript, and FastAPI, resulting in a 30% increase in user engagement.\\n\\nMigrated legacy monolithic Django application to a microservices architecture, improving system scalability and reducing API response time by 40%.\\n\\nDesigned and implemented CI/CD pipelines with GitHub Actions and Docker, automating testing and deployment processes.\\n\\nMentored 3 junior developers on best practices for React state management, Python code quality, and AWS security.\",\n",
      "    \"Full-Stack Developer | StartUpGrid, Austin, TX | July 2018 \\u2013 May 2020\\n\\nDeveloped and maintained core features for a project management platform using Django REST Framework and React.\\n\\nBuilt real-time notification features using WebSockets and Redis for pub/sub.\\n\\nOptimized database queries on PostgreSQL, reducing page load times by over 25%.\\n\\nCollaborated in an Agile team, participating in sprint planning, code reviews, and daily standups.\"\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"JavaScript (ES6+), TypeScript, Python, SQL, HTML5, CSS3\",\n",
      "    \"React, Redux, Redux Toolkit, Context API, Vite, Webpack, Jest, Cypress\",\n",
      "    \"Django, Django REST Framework, FastAPI, Flask, Celery\",\n",
      "    \"PostgreSQL, Redis, SQLite\",\n",
      "    \"AWS (EC2, S3, RDS, Lambda, IAM), Docker, GitHub Actions, CI/CD, Terraform\",\n",
      "    \"Git, Jira, Agile/Scrum, Figma, Confluence, Slack\"\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    \"CI/CD Pipeline Automator | github.com/jchen-dev/cicd-automator\\n\\nA custom Docker and GitHub Actions pipeline for automating testing, building, and deployment of Python/JS applications to AWS.\\n\\nReduced deployment time by 70% and eliminated manual deployment errors.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dummy_resume = \"\"\"\n",
    "Johnathan Chen\n",
    "San Francisco, CA | (555) 123-4567 | johnathan.chen@email.com | linkedin.com/in/johnathanchen | github.com/jchen-dev\n",
    "\n",
    "Summary\n",
    "Senior Full-Stack Developer with 6 years of experience building scalable web applications in fast-paced startup environments. Proven expertise in modern JavaScript (React) and Python (Django, FastAPI) stacks. Passionate about clean architecture, mentorship, and leveraging AWS to build efficient, cloud-native solutions.\n",
    "\n",
    "Technical Skills\n",
    "Languages: JavaScript (ES6+), TypeScript, Python, SQL, HTML5, CSS3\n",
    "\n",
    "Frontend: React, Redux, Redux Toolkit, Context API, Vite, Webpack, Jest, Cypress\n",
    "\n",
    "Backend: Django, Django REST Framework, FastAPI, Flask, Celery\n",
    "\n",
    "Databases: PostgreSQL, Redis, SQLite\n",
    "\n",
    "Cloud & DevOps: AWS (EC2, S3, RDS, Lambda, IAM), Docker, GitHub Actions, CI/CD, Terraform\n",
    "\n",
    "Tools & Methods: Git, Jira, Agile/Scrum, Figma, Confluence, Slack\n",
    "\n",
    "Professional Experience\n",
    "Senior Software Engineer | TechNova Inc., San Francisco, CA | June 2020 – Present\n",
    "\n",
    "Led the end-to-end development of a new B2B SaaS analytics dashboard using React, TypeScript, and FastAPI, resulting in a 30% increase in user engagement.\n",
    "\n",
    "Migrated legacy monolithic Django application to a microservices architecture, improving system scalability and reducing API response time by 40%.\n",
    "\n",
    "Designed and implemented CI/CD pipelines with GitHub Actions and Docker, automating testing and deployment processes.\n",
    "\n",
    "Mentored 3 junior developers on best practices for React state management, Python code quality, and AWS security.\n",
    "\n",
    "Key Technologies: Python, FastAPI, React, TypeScript, PostgreSQL, Redis, AWS (EC2, S3, Lambda), Docker, Jest\n",
    "\n",
    "Full-Stack Developer | StartUpGrid, Austin, TX | July 2018 – May 2020\n",
    "\n",
    "Developed and maintained core features for a project management platform using Django REST Framework and React.\n",
    "\n",
    "Built real-time notification features using WebSockets and Redis for pub/sub.\n",
    "\n",
    "Optimized database queries on PostgreSQL, reducing page load times by over 25%.\n",
    "\n",
    "Collaborated in an Agile team, participating in sprint planning, code reviews, and daily standups.\n",
    "\n",
    "Key Technologies: Python, Django, Django REST Framework, React, JavaScript, PostgreSQL, Redis, Jira\n",
    "\n",
    "Projects\n",
    "CI/CD Pipeline Automator | github.com/jchen-dev/cicd-automator\n",
    "\n",
    "A custom Docker and GitHub Actions pipeline for automating testing, building, and deployment of Python/JS applications to AWS.\n",
    "\n",
    "Reduced deployment time by 70% and eliminated manual deployment errors.\n",
    "\n",
    "Education\n",
    "Bachelor of Science in Computer Science | University of Texas at Austin | *2014 – 2018*\n",
    "\"\"\"\n",
    "result2 = get_resume_profile(dummy_resume , llm)\n",
    "print(json.dumps(result2 , indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jd_keywords(job_desc: str, llm)->JDKeyWords:\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=JDKeyWords)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI tool that is responsible for extracting hiring signals from job description.\"\n",
    "     \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "     (\"human\",\n",
    "      \"Job description:\\n {job_description}\\n\"\n",
    "      \"Be precise. Keep lists concise and deduplicated\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    jd = prompt | llm | parser\n",
    "    result = jd.invoke({\"job_description\": job_desc})\n",
    "    \n",
    "    return result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b56dd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_resume_report(job_desc: JDKeyWords , resume: ResumeProfile, llm)-> ResumeReport:\n",
    "    parser = JsonOutputParser(pydantic_object=ResumeReport)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are an AI tool that takes a structured JSON describing a job description and a Resume.\"\n",
    "         \"Your task is to analyze both to find matching skills and missing skills and make phrasing suggestions\"\n",
    "         \"You must make the suggestions in concrete bullet points\"\n",
    "         \"You must make a relevance_score of the resume and job description with a value between 0 and 100\"\n",
    "         \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "         (\"human\",\n",
    "          \"Keywords of Job Description:\\n\\n{job_description}\"\n",
    "          \"Structured information of the resume:\\n\\n{resume}\"\n",
    "          \"Be precise. Keep lists concise and deduplicated\")\n",
    "    ]).partial(format_instructions = parser.get_format_instructions())\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    result = chain.invoke({\"job_description\": job_desc,\"resume\":resume})\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f2a478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"matched_skills\": [\n",
      "    \"5+ years of professional experience in software development\",\n",
      "    \"React\",\n",
      "    \"Redux\",\n",
      "    \"TypeScript\",\n",
      "    \"Python\",\n",
      "    \"Django\",\n",
      "    \"FastAPI\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Redis\",\n",
      "    \"AWS (EC2, S3, RDS, Lambda)\",\n",
      "    \"Docker\",\n",
      "    \"CI/CD pipelines\",\n",
      "    \"Git\",\n",
      "    \"Agile/Scrum\"\n",
      "  ],\n",
      "  \"missed_skills\": [\n",
      "    \"Webpack\",\n",
      "    \"Redux Toolkit\",\n",
      "    \"RESTful API design principles\",\n",
      "    \"GitHub Actions\",\n",
      "    \"Testing frameworks (Jest, Pytest, Cypress)\",\n",
      "    \"Kubernetes\",\n",
      "    \"GraphQL\",\n",
      "    \"Terraform\"\n",
      "  ],\n",
      "  \"phrasing_suggestions\": [\n",
      "    \"\\u2022  Proficient in using Webpack for module bundling and optimization in React projects.\",\n",
      "    \"\\u2022  Experienced with Redux Toolkit for efficient state management in React applications.\",\n",
      "    \"\\u2022  Deep understanding of RESTful API design principles and best practices.\",\n",
      "    \"\\u2022  Successfully implemented and maintained CI/CD pipelines using GitHub Actions.\",\n",
      "    \"\\u2022  Proficient in various testing frameworks such as Jest, Pytest, and Cypress.\",\n",
      "    \"\\u2022  Familiar with Kubernetes for container orchestration and deployment.\",\n",
      "    \"\\u2022  Knowledge of GraphQL for building efficient and scalable APIs.\",\n",
      "    \"\\u2022  Experience with Terraform for infrastructure as code.\"\n",
      "  ],\n",
      "  \"relevance_score\": 85\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = generate_resume_report(result1 , result2 , llm)\n",
    "print(json.dumps(result , indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
