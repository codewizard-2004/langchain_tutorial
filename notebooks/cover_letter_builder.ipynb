{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4fdab5",
   "metadata": {},
   "source": [
    "# Cover Letter Generator\n",
    "In this notebook we are going to create a Cover letter generator RAG using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcfa90",
   "metadata": {},
   "source": [
    "## Workflow of Cover Letter Generator\n",
    "1. Input Collection\n",
    "* User uploads Resume (PDF/DOCX → parsed into text).\n",
    "* User pastes Job Description (JD).\n",
    "\n",
    "2. Keyword Extraction (LangChain pipeline #1)\n",
    "* Use an LLM + PydanticOutputParser to extract:\n",
    "    - role (e.g., \"Data Scientist\")\n",
    "    - seniority (e.g., \"Mid-level\")\n",
    "    - must_have (e.g., Python, SQL, Machine Learning)\n",
    "    - nice_to_have (e.g., Cloud, Docker, NLP)\n",
    "    - tools (e.g., TensorFlow, PyTorch, Tableau)\n",
    "✅ Output = structured JDKeywords object.\n",
    "\n",
    "3. Resume Analysis\n",
    "\n",
    "* Parse the resume into sections: Experience, Skills, Projects, Education.\n",
    "* Extract skills & experiences → again with a structured schema (e.g., ResumeProfile).\n",
    "\n",
    "4. Keyword Matching\n",
    "\n",
    "* Compare JD keywords vs Resume keywords.\n",
    "* Mark:\n",
    "    - ✅ Matches (strengths to emphasize).\n",
    "    - ❌ Gaps (skills missing → handled carefully, not overclaimed).\n",
    "\n",
    "5. Cover Letter Generation (LangChain pipeline #2)\n",
    "\n",
    "* Prompt template uses:\n",
    "    - JDKeywords (so letter aligns with employer’s needs).\n",
    "    - ResumeProfile (so letter emphasizes relevant experience).\n",
    "    - LLM writes a personalized cover letter, structured into:\n",
    "    - Greeting\n",
    "    - Hook (why the candidate is interested in this role/company)\n",
    "    - Body (match candidate’s experience → JD requirements)\n",
    "    - Closing (enthusiasm + call to action)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec55c5",
   "metadata": {},
   "source": [
    "configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b97f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "class Settings:\n",
    "    def __init__(self) -> None:\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        self.gemini_api = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        self.tavily_api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        \n",
    "    def load_gemini(self, temp: float = 0.5) -> ChatGoogleGenerativeAI:\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model = \"gemini-1.5-flash\",\n",
    "            api_key = self.gemini_api,\n",
    "            temperature = temp\n",
    "        )\n",
    "        print(\"LLM ready:\", type(llm).__name__)\n",
    "        return llm\n",
    "    def load_gemma(self, temp: float = 0.5)->ChatOpenAI:\n",
    "        \"\"\"\n",
    "        This method returns the local gemma3 model hosted by LM Studio.\n",
    "        \"\"\"\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"google/gemma-3-4b\",\n",
    "            openai_api_key = 'lm-studio', # type: ignore\n",
    "            openai_api_base=\"http://localhost:1234/v1\", # type: ignore\n",
    "            temperature=temp\n",
    "        )\n",
    "        return llm\n",
    "    \n",
    "    def load_tavily_search(self, max_results: int = 2) -> TavilySearchResults:\n",
    "        return TavilySearchResults(max_results = max_results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85290929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready: ChatGoogleGenerativeAI\n"
     ]
    }
   ],
   "source": [
    "config = Settings()\n",
    "llm = config.load_gemini()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498258a",
   "metadata": {},
   "source": [
    "## Define the schemas\n",
    "We will use this schemas to structure our outputs from LLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75277070",
   "metadata": {},
   "source": [
    "1. schema for extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45544a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class JDKeyWords(BaseModel):\n",
    "    role: Optional[str] = Field(None, description=\"Role inferred from job description\")\n",
    "    seniority: Optional[str] = Field(None, description=\"Seniority level like junior, senior, associate etc\")\n",
    "    must_have: List[str] = Field(..., description=\"Critical must-have skills needed for the job\")\n",
    "    nice_to_have: List[str] = Field(default_factory=list, description=\"Optional skills\")\n",
    "    tools: List[str] = Field(default_factory=list, description=\"Software/tools needed for this job\")\n",
    "\n",
    "# ... means the field is required\n",
    "# Optional[str] means it can be a string or None\n",
    "# if tools is empty then we will return a []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873bb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover_letter schema\n",
    "class CoverLetterOut(BaseModel):\n",
    "    cover_letter: str = Field(... , description=\"Generated cover letter text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fa3b4",
   "metadata": {},
   "source": [
    "## Creating Pipelines\n",
    "\n",
    "* pipeline to extract keywords from job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ae1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=JDKeyWords)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI tool that is responsible for extracting hiring signals from job description.\"\n",
    "     \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "     (\"human\",\n",
    "      \"Job description:\\n {job_description}\\n\"\n",
    "      \"Be precise. Keep lists concise and deduplicated\")\n",
    "]).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "jd = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c75e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc = \"\"\"\n",
    "Job Description: Senior Full-Stack Developer\n",
    "Company: InnovateTech Solutions\n",
    "Location: San Francisco, CA (Hybrid Remote)\n",
    "Job Type: Full-Time\n",
    "\n",
    "About Us\n",
    "At InnovateTech Solutions, we're building the next generation of SaaS tools that empower businesses to thrive. Our platform leverages cutting-edge AI and data analytics to provide actionable insights. Join our passionate team of engineers and play a key role in shaping our product's future.\n",
    "\n",
    "The Role\n",
    "We are seeking a highly skilled and motivated Senior Full-Stack Developer to design, develop, and implement robust software solutions. You will be involved in all stages of the product lifecycle, from concept to deployment, and will mentor junior developers on the team. This is a fantastic opportunity to make a significant impact on a product used by thousands.\n",
    "\n",
    "Key Responsibilities\n",
    "Design, code, test, and manage full-stack applications from the database to the UI.\n",
    "\n",
    "Collaborate with product managers, designers, and other engineers to define, design, and ship new features.\n",
    "\n",
    "Lead technical architecture discussions and make recommendations on system improvements.\n",
    "\n",
    "Write clean, maintainable, and efficient code while following best practices.\n",
    "\n",
    "Conduct code reviews and provide constructive feedback to team members.\n",
    "\n",
    "Identify and troubleshoot complex performance and scalability issues.\n",
    "\n",
    "Must-Have Qualifications\n",
    "5+ years of professional experience in software development.\n",
    "\n",
    "Frontend: Proven expertise with modern JavaScript frameworks, specifically React and its ecosystem (Redux, Webpack, Hooks).\n",
    "\n",
    "Backend: Strong proficiency in Python and experience with web frameworks, specifically Django or FastAPI.\n",
    "\n",
    "Database: Experience with both PostgreSQL and Redis.\n",
    "\n",
    "Cloud & DevOps: Hands-on experience with AWS (EC2, S3, RDS, Lambda) and familiarity with Docker and CI/CD pipelines.\n",
    "\n",
    "Solid understanding of RESTful API design principles.\n",
    "\n",
    "Experience with version control using Git.\n",
    "\n",
    "Nice-to-Have Qualifications\n",
    "Experience with TypeScript.\n",
    "\n",
    "Knowledge of GraphQL.\n",
    "\n",
    "Familiarity with testing frameworks (e.g., Jest, Pytest, Cypress).\n",
    "\n",
    "Understanding of agile/scrum development methodologies.\n",
    "\n",
    "Previous experience in a startup or SaaS environment.\n",
    "\n",
    "Experience with Kubernetes.\n",
    "\n",
    "Tools You'll Use\n",
    "Frontend: React, Redux Toolkit, TypeScript, Vite, Jest\n",
    "\n",
    "Backend: Python, Django REST Framework, FastAPI, Celery\n",
    "\n",
    "Database: PostgreSQL, Redis\n",
    "\n",
    "Infrastructure: AWS, Docker, GitHub Actions, Terraform\n",
    "\n",
    "Collaboration: Jira, Slack, Figma, Confluence\n",
    "\n",
    "What We Offer\n",
    "Competitive salary and equity package.\n",
    "\n",
    "Comprehensive health, dental, and vision insurance.\n",
    "\n",
    "401(k) with company matching.\n",
    "\n",
    "Flexible work schedule and generous PTO.\n",
    "\n",
    "Professional development budget.\n",
    "\n",
    "A collaborative, inclusive, and innovative culture.\n",
    "\n",
    "How to Apply\n",
    "\n",
    "If you are excited about this opportunity, please apply with your resume and a link to your GitHub profile or portfolio.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9af12ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jd_keywords(job_desc: str, llm)->JDKeyWords:\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=JDKeyWords)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are an AI tool that is responsible for extracting hiring signals from job description.\"\n",
    "     \"Return ONLY valid JSON that matches this schema: \\n{format_instructions}\"),\n",
    "     (\"human\",\n",
    "      \"Job description:\\n {job_description}\\n\"\n",
    "      \"Be precise. Keep lists concise and deduplicated\")\n",
    "    ]).partial(format_instructions=parser.get_format_instructions())\n",
    "    jd = prompt | llm | parser\n",
    "    result = jd.invoke({\"job_description\": job_desc})\n",
    "    \n",
    "    return result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa766ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"Senior Full-Stack Developer\",\n",
      "  \"seniority\": null,\n",
      "  \"must_have\": [\n",
      "    \"5+ years of professional experience in software development\",\n",
      "    \"Proven expertise with modern JavaScript frameworks, specifically React and its ecosystem (Redux, Webpack, Hooks)\",\n",
      "    \"Strong proficiency in Python and experience with web frameworks, specifically Django or FastAPI\",\n",
      "    \"Experience with both PostgreSQL and Redis\",\n",
      "    \"Hands-on experience with AWS (EC2, S3, RDS, Lambda)\",\n",
      "    \"Solid understanding of RESTful API design principles\",\n",
      "    \"Experience with version control using Git\"\n",
      "  ],\n",
      "  \"nice_to_have\": [\n",
      "    \"Experience with TypeScript\",\n",
      "    \"Knowledge of GraphQL\",\n",
      "    \"Familiarity with testing frameworks (e.g., Jest, Pytest, Cypress)\",\n",
      "    \"Understanding of agile/scrum development methodologies\",\n",
      "    \"Previous experience in a startup or SaaS environment\",\n",
      "    \"Experience with Kubernetes\"\n",
      "  ],\n",
      "  \"tools\": [\n",
      "    \"React\",\n",
      "    \"Redux Toolkit\",\n",
      "    \"TypeScript\",\n",
      "    \"Vite\",\n",
      "    \"Jest\",\n",
      "    \"Python\",\n",
      "    \"Django REST Framework\",\n",
      "    \"FastAPI\",\n",
      "    \"Celery\",\n",
      "    \"PostgreSQL\",\n",
      "    \"Redis\",\n",
      "    \"AWS\",\n",
      "    \"Docker\",\n",
      "    \"GitHub Actions\",\n",
      "    \"Terraform\",\n",
      "    \"Jira\",\n",
      "    \"Slack\",\n",
      "    \"Figma\",\n",
      "    \"Confluence\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm2 = config.load_gemma()\n",
    "\n",
    "result = generate_jd_keywords(job_desc , llm2)\n",
    "print(json.dumps(result , indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
