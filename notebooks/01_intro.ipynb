{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7caba6",
   "metadata": {},
   "source": [
    "# Introduction to LANGCHAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a97d8",
   "metadata": {},
   "source": [
    "initializing gemini api keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115c4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load all variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "google_key = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ffb70",
   "metadata": {},
   "source": [
    "LangChain is a framework for building applications with LLMs (Large Language Models).\n",
    "Think of it like a toolbox that helps you:\n",
    "\n",
    "* Connect an LLM (like GPT, LLaMA, etc.)\n",
    "* Chain steps together (e.g., prompt → model → reasoning → output)\n",
    "* Add memory (so it “remembers” conversations)\n",
    "* Integrate external knowledge (databases, PDFs, APIs, etc.)\n",
    "* Build Agents that can make decisions and use tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620d20a",
   "metadata": {},
   "source": [
    "* **ChatGoogleGenerativeAI** : Gemini Connector, helps langchain connect with gemini\n",
    "* **LLMChain** : A chain in langchain is a simple workflow and LLMChain is the simplest. It takes a prompt and sends to llm and returns the result.\n",
    "    - temperature: controls the creativity of llm (higher = more cretive)\n",
    "* **PromptTemplate**: It is a reusable template/blueprint for prompts.\n",
    "\n",
    "Here we created a simple chain \n",
    "Inputs -> Prompt -> LLM -> Ouptput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf5cb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal': 'dog', 'text': \"**For a Male Dog:**\\n\\n* **Classic:**  Duke, Charlie, Cooper, Jack, Buddy\\n* **Unique:**  Arlo, Finn, Jasper,  Reggie,  Ziggy\\n* **Strong:**  Ranger,  Thor,  Magnus,  Atlas,  Bear\\n\\n**For a Female Dog:**\\n\\n* **Classic:**  Lucy, Bella, Daisy, Sophie, Chloe\\n* **Unique:**  Willow,  Juniper,  Hazel,  Piper,  Rhea\\n* **Sweet:**  Sugar,  Honey,  Lily,  Rose,  Buttercup\\n\\n\\n**Based on Appearance:**\\n\\n* **If they're fluffy:** Cloud,  Cotton,  Snowball\\n* **If they're small:**  Peanut,  Pip,  Squirt\\n* **If they're big:**  Titan,  Giant,  Mountain\\n\\n\\nTo help me give you a better suggestion, tell me:\\n\\n* **What is the dog's breed or appearance?**\\n* **What is the dog's personality like?** (Playful, calm, energetic, etc.)\\n* **What kind of name are you looking for?** (Cute, strong, sophisticated, etc.)\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-flash\",\n",
    "    api_key = google_key,\n",
    "    temperature = 0.7\n",
    ")\n",
    "\n",
    "#create a prompt template with a placeholder for an animal\n",
    "prompt = PromptTemplate.from_template(\"Suggest a name for a {animal}.\")\n",
    "#wrap it into a chain\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")\n",
    "#run the chain\n",
    "print(chain.invoke({\"animal\": \"dog\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cf967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate.from_template(\"Suggest a name for a {company} that makes {product} and a tagline.\")\n",
    "\n",
    "chain2 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b08120",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain2.invoke({\"company\":\"Chemical\" , \"product\":\"soap\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f0712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Chemical', 'product': 'soap', 'text': \"Here are a few name and tagline suggestions for a chemical that makes soap:\\n\\n**Option 1 (Emphasizing ease of use):**\\n\\n* **Name:**  SaponifyEasy\\n* **Tagline:**  Soapmaking simplified.\\n\\n**Option 2 (Highlighting effectiveness):**\\n\\n* **Name:**  SudsSurge\\n* **Tagline:** The power of soap, unleashed.\\n\\n**Option 3 (Focusing on natural ingredients - if applicable):**\\n\\n* **Name:**  BotanicaBase\\n* **Tagline:**  Naturally superior soapmaking.\\n\\n\\n**Option 4 (More scientific and sophisticated):**\\n\\n* **Name:**  LyeLuxe (if it's lye-based) or  EsterEase (if it's ester-based)\\n* **Tagline:**  Precision soapmaking, perfected.\\n\\n\\n**Option 5 (Short and catchy):**\\n\\n* **Name:**  SoapStart\\n* **Tagline:**  Your soapmaking journey begins here.\\n\\n\\nWhen choosing, consider:\\n\\n* **Target audience:**  Are you selling to hobbyists, large manufacturers, or both?\\n* **Key selling points:** What makes your chemical unique or superior?\\n* **Brand personality:** Do you want to project a scientific, natural, or easy-going image?\\n\\n\\nRemember to check for trademark availability before settling on a name.\"}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebccc87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few name and tagline suggestions for a chemical that makes soap:\n",
      "\n",
      "**Option 1 (Emphasizing ease of use):**\n",
      "\n",
      "* **Name:**  SaponifyEasy\n",
      "* **Tagline:**  Soapmaking simplified.\n",
      "\n",
      "**Option 2 (Highlighting effectiveness):**\n",
      "\n",
      "* **Name:**  SudsSurge\n",
      "* **Tagline:** The power of soap, unleashed.\n",
      "\n",
      "**Option 3 (Focusing on natural ingredients - if applicable):**\n",
      "\n",
      "* **Name:**  BotanicaBase\n",
      "* **Tagline:**  Naturally superior soapmaking.\n",
      "\n",
      "\n",
      "**Option 4 (More scientific and sophisticated):**\n",
      "\n",
      "* **Name:**  LyeLuxe (if it's lye-based) or  EsterEase (if it's ester-based)\n",
      "* **Tagline:**  Precision soapmaking, perfected.\n",
      "\n",
      "\n",
      "**Option 5 (Short and catchy):**\n",
      "\n",
      "* **Name:**  SoapStart\n",
      "* **Tagline:**  Your soapmaking journey begins here.\n",
      "\n",
      "\n",
      "When choosing, consider:\n",
      "\n",
      "* **Target audience:**  Are you selling to hobbyists, large manufacturers, or both?\n",
      "* **Key selling points:** What makes your chemical unique or superior?\n",
      "* **Brand personality:** Do you want to project a scientific, natural, or easy-going image?\n",
      "\n",
      "\n",
      "Remember to check for trademark availability before settling on a name.\n"
     ]
    }
   ],
   "source": [
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d42a61",
   "metadata": {},
   "source": [
    "# Connecting two chains\n",
    "\n",
    "* chain1 -> chain2\n",
    "* chain1: write a story based on a {topic}\n",
    "* chain2: Takes that story and generate a cachy title for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd6efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screams of the living mingled with the moans of the undead as the horde surged through the barricaded streets, their hunger insatiable, their pursuit relentless.  Only a handful remained, huddled in the flickering light of a dying generator, their hope as fragile as the splintered wood protecting them.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "#chain 1: Story Generator\n",
    "prompt1 = PromptTemplate.from_template(\n",
    "    \"Write a story in 1-2 sentences about {topic}.\"\n",
    ")\n",
    "chain1 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt1,\n",
    "    output_key = \"story\"\n",
    ")\n",
    "\n",
    "#chain1 generates a story and stores it in key \"story\"\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(\n",
    "    \"Generate one creative title for this story: \\n{story}.\"\n",
    ")\n",
    "chain2 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt2,\n",
    "    output_key = \"title\"\n",
    ")\n",
    "\n",
    "#create a sequential chain to connect chain1 and chain2\n",
    "story_chain = SequentialChain(\n",
    "    chains = [chain1 , chain2],\n",
    "    input_variables = [\"topic\"],\n",
    "    output_variables = [\"story\" , \"title\"],\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "output = story_chain.invoke({\n",
    "    \"topic\": \"Zombie attack\"\n",
    "})\n",
    "\n",
    "print(output[\"story\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce5f635a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Flicker\n"
     ]
    }
   ],
   "source": [
    "print(output[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11272e",
   "metadata": {},
   "source": [
    "* Here chain1 generates a story and saves under tag \"story\"\n",
    "* chain2 uses this story to generate a title and stores under key \"title\"\n",
    "\n",
    "* verbose=False (default) → Runs quietly, you only see the final result.\n",
    "* verbose=True → Prints extra details in your console, like:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
