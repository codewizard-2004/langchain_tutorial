{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c618c953",
   "metadata": {},
   "source": [
    "# 4. Tools and Agents\n",
    "\n",
    "## Syllabus\n",
    "* 4.1 Introduction to Tools\n",
    "* 4.2 Introduction to Agents\n",
    "* 4.3 Built-in Tools in LangChain\n",
    "* 4.4 Agents in Action\n",
    "* 4.5 Building a Multi-Tool Agent\n",
    "* 4.6 Creating Custom Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb601f33",
   "metadata": {},
   "source": [
    "### 4.1 Introduction to Tools\n",
    "A tool in LangChain is simply a function that LLM uses when it cannot do on its own.\n",
    "eg. A calculator is a tool that an LLM can use because LLM's can make math mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a900558",
   "metadata": {},
   "source": [
    "Every tool has 3 main parts\n",
    "* Name: Unique identifier used by the agent\n",
    "* Description: Natural language instruction so the agent knows when to use it\n",
    "* Function: Actual python function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625216f",
   "metadata": {},
   "source": [
    "## 4.2 Built-in Tools in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef1d81",
   "metadata": {},
   "source": [
    "#### Tool Example 1: Calculator Tool\n",
    "\n",
    "* `PythonREPLTool()` gives the LLM access to a Python REPL(read, eval, print, loop)\n",
    "* It executes the given string as a python code\n",
    "* creates a small sandbox python interpretor\n",
    "* does not require an LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d9c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c5c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready: ChatGoogleGenerativeAI\n"
     ]
    }
   ],
   "source": [
    "# initializing the llm\n",
    "from llm.load_llm import initialize_llm\n",
    "\n",
    "llm = initialize_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2841a",
   "metadata": {},
   "source": [
    "`pip install langchain-experimental`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.0\n",
      "\n",
      "69\n",
      "\n",
      "55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "calculator = PythonREPLTool()\n",
    "\n",
    "# Add print() to see the results\n",
    "print(calculator.run(\"print(5*12+(33/3))\"))\n",
    "print(calculator.run(\"print(max(25,69))\"))\n",
    "print(calculator.run(\"print(sum([i for i in range(1,11)]))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901628f",
   "metadata": {},
   "source": [
    "`LLMMathChain`\n",
    "* Instead of directly executing code, it asks the LLM to write math as python code, then evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3767d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_25156\\943593853.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(math_chain.run(\"What is (5*12+(33/3))\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is (5*12+(33/3))\u001b[32;1m\u001b[1;3m```text\n",
      "(5*12+(33/3))\n",
      "```\n",
      "...numexpr.evaluate(\"(5*12+(33/3))\")...\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m71.0\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: 71.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "math_chain = LLMMathChain.from_llm(llm = llm, verbose = True)\n",
    "print(math_chain.run(\"What is (5*12+(33/3))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098071ad",
   "metadata": {},
   "source": [
    "#### Tool Example 2: Search Tool\n",
    "* LLM's don't have access to fresh information like daily news, stock prices, weather etc\n",
    "* To fix this, we connect them to a search API.\n",
    "\n",
    "* There are a few tools for searching\n",
    "    - Tavily Search API\n",
    "    - SerpAPI\n",
    "    - DuckDuckGoSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8eafa",
   "metadata": {},
   "source": [
    "`pip install tavily-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966ba0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "tavily_key = os.environ.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525e5b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_5012\\1064741316.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  search = TavilySearchResults(max_results = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Kochi, India Hourly Weather Forecast | Weather Underground', 'url': 'https://www.wunderground.com/hourly/VOCC/date/2024-4-12', 'content': 'Considerable cloudiness with occasional rain showers. Hazy. Low around 75F. Winds NNW at 5 to 10 mph. Chance of rain 50%.\\n\\nicon\\nicon\\nicon\\nicon\\nicon\\nAccess Logo\\n\\nWe recognize our responsibility to use data and technology for good. We may use or share your data with our data vendors. Take control of your data.\\n\\nThe Weather Company Logo\\nThe Weather Channel Logo\\nWeather Underground Logo\\nStorm Radar Logo\\n\\n¬© The Weather Company, LLC 2025 [...] # Kochi, Kerala, India Hourly Weather Forecaststar\\\\_ratehome\\n\\nicon\\n\\nThank you for reporting this station. We will review the data in question.\\n\\nYou are about to report this weather station for bad data. Please select the information that is incorrect.\\n\\nSee more\\n\\n(Reset Map)\\n\\nNo PWS\\n\\nReset Map, or Add PWS.\\n\\nicon\\n\\nOvercast with rain showers at times. Hazy. High 82F. Winds WNW at 5 to 10 mph. Chance of rain 40%.\\n\\nicon', 'score': 0.72884524}, {'title': '10-Day Weather Forecast for Kochi, Kerala, India', 'url': 'https://weather.com/weather/tenday/l/Kochi+Kerala+India?canonicalCityId=ffce352223d404923ebf9b5d4b077b63', 'content': \"## Recent Locations\\n\\n## Weather Forecasts\\n\\n## Radar & Maps\\n\\n## News & Media\\n\\n## Products & Account\\n\\n## Lifestyle\\n\\n### Specialty Forecasts\\n\\n# 10 Day Weather-Kochi, Kerala, India\\n\\n## Today\\n\\n## Day\\n\\nCloudy with a few showers. Hazy. High 82F. Winds NW at 10 to 15 mph. Chance of rain 30%.\\n\\nundefined\\n\\nHeads-up\\n\\nThousands Of Lightning Strikes Spark New Wildfires\\n\\n## Night\\n\\nOvercast with showers at times. Hazy. Low around 75F. Winds NNW at 5 to 10 mph. Chance of rain 50%.\\n\\n## Fri 05\\n\\n## Day [...] The Weather Channel is the world's most accurate forecaster according to ForecastWatch, Global and Regional Weather Forecast Accuracy Overview, 2021-2024, commissioned by The Weather Company.\\n\\nWeather Channel\\n\\n¬© The Weather Company, LLC 2025 [...] Increasing clouds with showers arriving sometime after midnight. Hazy. Low 77F. Winds N at 5 to 10 mph. Chance of rain 40%.\\n\\n## Tue 09\\n\\n## Day\\n\\nMostly cloudy skies early, then partly cloudy in the afternoon. Hazy. High 84F. Winds NW at 10 to 15 mph.\\n\\n## Night\\n\\nIncreasing clouds with showers arriving sometime after midnight. Hazy. Low 76F. Winds NNW at 5 to 10 mph. Chance of rain 50%.\\n\\n## Wed 10\\n\\n## Day\\n\\nMostly cloudy. Hazy. High 84F. Winds NW at 10 to 15 mph.\\n\\n## Night\", 'score': 0.588062}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results = 2)\n",
    "\n",
    "results = search.run(\"What is the latest weather in Kochi, Kerala, India\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e766dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We recognize our responsibility to use data and technology for good. We may use or share your data with our data vendors. Take control of your data.\n",
      "\n",
      "The Weather Channel is the world's most accurate forecaster according to ForecastWatch, Global and Regional Weather Forecast Accuracy Overview, 2021-2024, commissioned by The Weather Company.\n",
      "\n",
      "Weather Channel\n",
      "\n",
      "¬© The Weather Company, LLC 2025 [...] ## Day\n",
      "\n",
      "A few showers this morning with overcast skies during the afternoon hours. Hazy. High 84F. Winds NW at 10 to 15 mph. Chance of rain 40%.\n",
      "\n",
      "## Night\n",
      "\n",
      "Considerable cloudiness. Occasional rain showers after midnight. Hazy. Low 76F. Winds NW at 5 to 10 mph. Chance of rain 50%.\n",
      "\n",
      "## Wed 03\n",
      "\n",
      "## Day\n",
      "\n",
      "Rain showers early with overcast skies later in the day. Hazy. High 83F. Winds NW at 10 to 15 mph. Chance of rain 60%.\n",
      "\n",
      "## Night [...] ## Recent Locations\n",
      "\n",
      "## Weather Forecasts\n",
      "\n",
      "## Radar & Maps\n",
      "\n",
      "## News & Media\n",
      "\n",
      "## Products & Account\n",
      "\n",
      "## Lifestyle\n",
      "\n",
      "### Specialty Forecasts\n",
      "\n",
      "# Kochi, Kerala, India\n",
      "\n",
      "## Weather Today in Kochi, Kerala, India\n",
      "\n",
      "6:15 am\n",
      "\n",
      "6:33 pm\n",
      "\n",
      "## Radar\n",
      "\n",
      "## Rain\n",
      "\n",
      "Rain ending around 10:00 AM.\n",
      "\n",
      "# Hourly Weather-Kochi, Kerala, India\n",
      "\n",
      "## Now\n",
      "\n",
      "Mostly Cloudy\n",
      "\n",
      "## 11 am\n",
      "\n",
      "Mostly Cloudy\n",
      "\n",
      "## 12 pm\n",
      "\n",
      "Mostly Cloudy\n",
      "\n",
      "## 1 pm\n",
      "\n",
      "Mostly Cloudy\n",
      "\n",
      "Chart small gif\n",
      "\n",
      "## Don't Miss\n",
      "\n",
      "## Travel\n",
      "\n",
      "# 10 Day Weather-Kochi, Kerala, India\n",
      "\n",
      "## Today\n"
     ]
    }
   ],
   "source": [
    "print(results[0][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c104f",
   "metadata": {},
   "source": [
    "* Alternatively we can use `DuckDuckGo search` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11653607",
   "metadata": {},
   "source": [
    "### Using Search in an Agent\n",
    "üìå Here‚Äôs what happens:\n",
    "- LLM sees the question.\n",
    "- Decides ‚Üí ‚ÄúI don‚Äôt know Bitcoin‚Äôs price, I must use search.‚Äù\n",
    "- Calls search tool ‚Üí fetches live price.\n",
    "- Passes that result into the calculator.\n",
    "- Returns final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "695ddd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_25156\\1698668514.py:7: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Bitcoin in USD, then divide it by 3.  I'll use a search engine to get the current price.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"current Bitcoin price USD\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Bitcoin price today, BTC to USD live price, marketcap and chart', 'url': 'https://coinmarketcap.com/currencies/bitcoin/', 'content': 'The live Bitcoin price today is $110,304 USD with a 24-hour trading volume of $67,781,659,091 USD. We update our BTC to USD price in real-time. Bitcoin is up 2.63% in the last 24 hours. The current CoinMarketCap ranking is #1, with a live market cap of $2,196,700,158,553 USD. It has a circulating supply of 19,914,996 BTC coins and a max. supply of 21,000,000 BTC coins. [...] Thanks to its pioneering nature, BTC remains at the top of this energetic market after over a decade of existence. Even after Bitcoin has lost its undisputed dominance, it remains the largest cryptocurrency, with a market capitalization that surpassed the $1 trillion mark in 2021, after Bitcoin price hit an all-time high of $64,863.10 on April 14, 2021. This is owing in large part to growing institutional interest in Bitcoin, and the ubiquitousness of platforms that provide use-cases for BTC: [...] price today in mid-September 2021, those pizzas would be worth an astonishing $478 million. This event is now known as ‚ÄúBitcoin Pizza Day.‚Äù In July 2010, Bitcoin first started trading, with the Bitcoin price ranging from $0.0008 to $0.08 at that time.', 'score': 0.91901255}, {'title': 'BTCUSD Bitcoin US Dollar - Currency Exchange Rate Live Price Chart', 'url': 'https://tradingeconomics.com/btcusd:cur', 'content': '## Bitcoin US Dollar traded at 110279 this Tuesday September 2nd, increasing 1025 or 0.94 percent since the previous trading session. Looking back, over the last four weeks, Bitcoin gained 3.45 percent. Over the last 12 months, its price rose by 91.05 percent. Looking ahead, we forecast Bitcoin US Dollar to be priced at 106560 by the end of this quarter and at 99829 in one year, according to Trading Economics global macro models projections and analysts expectations. [...] |  | Actual | Chg | %Chg |\\n ---  --- |\\n| United States | 4.2510 | 0.009 | -0.01% |\\n| United Kingdom | 4.7540 | 0.030 | 0.03% |\\n| Japan | 1.6110 | 0.014 | -0.01% |\\n| Australia | 4.3570 | 0.022 | 0.02% |\\n| Germany | 2.7490 | 0.027 | 0.03% |\\n| Brazil | 13.9800 | 0.085 | 0.09% |\\n| Russia | 13.8500 | 0.050 | -0.05% |\\n| India | 6.5900 | 0.019 | -0.02% |\\n| Canada | 3.3750 | 0.053 | -0.05% |\\n| Italy | 3.6361 | 0.021 | 0.02% |\\n| France | 3.5362 | 0.024 | 0.02% | [...] | Crosses | Price |  | Day | %Day | %Year | Date |\\n ---  ---  --- \\n| BTCUSD | 110221 |  | 967 | 0.89% | 90.94% | Sep/02 |\\n| ETHUSD | 4,379.50 |  | 65.60 | 1.52% | 78.99% | Sep/02 |\\n| ADAUSD | 0.81783 |  | 0.01770 | 2.21% | 155.33% | Sep/02 |\\n| SOLUSD | 202.5763 |  | 5.4979 | 2.79% | 58.02% | Sep/02 |\\n| XRPUSD | 2.80200 |  | 0.04930 | 1.79% | 400.28% | Sep/02 |\\n| MTCUSD | 0.27 |  | -0.002 | -0.63% | -33.13% | Sep/02 |\\n| DAIUSD | 0.99969 |  | -0.00010 | -0.01% | -0.02% | Sep/02 |', 'score': 0.8690161}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought:The search results give a Bitcoin price around $110,304. I will use Python to divide this by 3.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input: ```python\n",
      "price = 110304\n",
      "print(price / 3)\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m36768.0\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
      "Final Answer: $36768.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$36768.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Give the agent tools (search + calculator)\n",
    "tools = [search, calculator]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Now the LLM can decide when to search\n",
    "agent.run(\"What is the current price of Bitcoin in USD divided by 3?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523fc9f",
   "metadata": {},
   "source": [
    "## 4.3 Creating Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f11ef23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "# define a custom tool with a decorator function\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\" Get the weather for a given city from these dummy data\"\"\"\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 25¬∞C\",\n",
    "        \"London\": \"Rainy, 15¬∞C\",\n",
    "        \"Tokyo\": \"Cloudy, 20¬∞C\"\n",
    "    }\n",
    "\n",
    "    return weather_data[city]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdf672",
   "metadata": {},
   "source": [
    "using it in an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6daaa275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to get the weather for London.  I will use the `get_weather` function.\n",
      "Action: get_weather\n",
      "Action Input: London\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRainy, 15¬∞C\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: The weather in London is rainy and 15¬∞C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in London is rainy and 15¬∞C.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [get_weather]\n",
    "\n",
    "agent2 = initialize_agent(\n",
    "    tools = tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose= True\n",
    ")\n",
    "\n",
    "agent2.run(\"Whats the weather in London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0393417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def matrix_determinant(matrix: str)->str:\n",
    "    \"\"\"\n",
    "    Calculates the determinant of a 2x2 matrix\n",
    "    Input: 2x2 matrix in string format\n",
    "    Output: determinant value in string\n",
    "    \"\"\"\n",
    "    arr = np.array(eval(matrix))\n",
    "    det = np.linalg.det(arr)\n",
    "    return f\"The determinant is {det}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bccd295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_20944\\968028663.py:4: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent3 = initialize_agent(\n",
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_20944\\968028663.py:11: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent3.run(\"Determine the determinant of matrix [[1,2],[3,4]]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate the determinant of the given 2x2 matrix.  I can use the `matrix_determinant` function for this.\n",
      "Action: matrix_determinant\n",
      "Action Input: \"[[1,2],[3,4]]\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe determinant is -2.0000000000000004\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: -2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "tools3 = [matrix_determinant]\n",
    "agent3 = initialize_agent(\n",
    "    llm = llm,\n",
    "    tools = tools3,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "agent3.run(\"Determine the determinant of matrix [[1,2],[3,4]]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942c3231",
   "metadata": {},
   "source": [
    "## 4.4 Introduction to Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3332d",
   "metadata": {},
   "source": [
    "An agent is like an AI decision maker that\n",
    "* takes in a user query as input\n",
    "* Decides how to solve it (tool or reasoning)\n",
    "* uses the chosen tools\n",
    "* returns the final answer\n",
    "\n",
    "eg. What is the square root of population of Japan.\n",
    "* Pick at tool:\n",
    "    - Search tool to get population\n",
    "    - Calculator tool to get square root\n",
    "    - Database tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046d5e8",
   "metadata": {},
   "source": [
    "#### ReAct Framework (Reason + Act)\n",
    "* The agent reasons step by step\n",
    "* Then it acts by using tools.\n",
    "\n",
    "eg. for previous example\n",
    "* Reason: I don't know the population of Japan?\n",
    "* Act: Use the search tool\n",
    "* Observation: 125M\n",
    "* Reason: I need to calculate the root of 125M\n",
    "* Act: use the calculator\n",
    "* Observation: result is 11180\n",
    "* Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda1ea4",
   "metadata": {},
   "source": [
    "#### Agent Execution Loop\n",
    "\n",
    "This is the core cycle of how agents work:\n",
    "\n",
    "1. Thought ‚Üí The agent reasons internally. (\"I need Japan‚Äôs population.\")\n",
    "2. Action ‚Üí Calls a tool. (\"Search for Japan population.\")\n",
    "3. Observation ‚Üí Gets result from tool. (\"125M.\")\n",
    "4. Thought ‚Üí Decides next step. (\"Now calculate the square root.\")\n",
    "5. Action ‚Üí Uses calculator.\n",
    "6. Observation ‚Üí Gets the number.\n",
    "7. Response ‚Üí Returns final answer to user.\n",
    "\n",
    "üëâ This loop continues until the agent has enough info to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb895d",
   "metadata": {},
   "source": [
    "## 4.5 Agents in Action\n",
    "\n",
    "#### Zero-Shot ReAct Description Agent\n",
    "\n",
    "* Zero-Shot ‚Üí means the agent hasn‚Äôt been given examples ahead of time.\n",
    "* ReAct ‚Üí means it uses the Reason + Act loop we discussed.\n",
    "* Description ‚Üí it decides which tool to use based only on the natural language description of tools.\n",
    "\n",
    "üëâ Example tools given to the agent:\n",
    "\n",
    "Calculator: \"Useful for math operations like addition, subtraction, multiplication, division, or square roots.\"\n",
    "\n",
    "Search: \"Useful for finding real-world facts from the internet.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f7291",
   "metadata": {},
   "source": [
    "* Lets build a small agent that takes in names of some countries\n",
    "* Finds their population\n",
    "* Square roots them and store it in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ddb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "import math\n",
    "import csv\n",
    "# Calculator Tool\n",
    "@tool\n",
    "def square_root_tool(population: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool takes in a population as string and returns its square root in string format\n",
    "    \"\"\"\n",
    "    value = int(population)\n",
    "    return str(math.sqrt(value))\n",
    "\n",
    "@tool\n",
    "def write_to_csv(row: str) -> None:\n",
    "    \"\"\"\n",
    "    This tool takes a row as string and writes it into a csv file.\n",
    "    The input must be of the form city,population,square_root_of_population.\n",
    "    eg: \"Tokyo 125000000 11180\"\n",
    "    \"\"\"\n",
    "    item = row.split(\" \")\n",
    "    file = open(\"output.csv\" , \"a+\")\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(item)\n",
    "    file.close()\n",
    "\n",
    "@tool\n",
    "def read_from_csv(dummy: str = \"read\") -> str:\n",
    "    \"\"\"\n",
    "    This tool reads rows from the csv file and returns them as a string.\n",
    "    Input is ignored (just pass anything).\n",
    "    \"\"\"\n",
    "    with open(\"output.csv\", \"r\") as file:\n",
    "        data = file.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa007e3c",
   "metadata": {},
   "source": [
    "creating an agent that will take a couple of cities, find its population, find it square root and save it into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9161343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the population of London, Tokyo, and New York.  I'll use a search engine for that. Then I'll calculate the square root of each population and write the city, population, and square root to a CSV file. Finally, I'll read and display the contents of the CSV file.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"population of London, population of Tokyo, population of New York\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'London Population 2025', 'url': 'https://worldpopulationreview.com/cities/united-kingdom/london', 'content': \"The first half of the 20th century saw sustained, and fairly rapid growth and London‚Äôs population reached its highest point in 1939. By the outbreak of the second world war, 8,615,245 people were living in London, although by then it had just lost its status as the largest city in the world to New York. [...] London's 2025 population is now estimated at 9,840,740. In 1950, the population of London was 8,360,850. London has grown by 92,710 in the last year, which represents a 0.95% annual change.These population estimates and projections come from the latest revision of the UN World Urbanization Prospects. These estimates represent the Urban agglomeration of London, which typically includes London's population in addition to adjacent suburban areas.\\n\\n9.8M\\n\\nTotal Population\\n\\n92.7K\\n0.95%\\n\\nGrowth\\n\\nYes\", 'score': 0.49509352}, {'title': 'London - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/London', 'content': 'In 2008 Time \"Time (magazine)\") magazine named London alongside New York City and Hong Kong as Nylonkong, hailing them as the world\\'s three most influential global cities. In January 2015 Greater London\\'s population was estimated to be 8.63 million, its highest since 1939. During the Brexit referendum in 2016, the UK as a whole decided to leave the European Union, but most London constituencies voted for remaining. However, Britain\\'s exit from the EU in January 2020 only marginally weakened [...] London is the capital and largest city of both England and the United Kingdom, with a population of 9,841,000 in 2025. Its wider metropolitan area is the largest in Western Europe, with a population of 15.1 million. London stands on the River Thames in southeast England, at the head of a 50-mile (80 km) tidal estuary down to the North Sea, and has been a major settlement for nearly 2,000 years. Its ancient core and financial centre, the City of London, was founded by the Romans as Londinium and', 'score': 0.42591617}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to extract the populations from the search results.  The results aren't perfectly consistent, so I'll choose the most recent and reliable-looking numbers. Then I'll calculate the square roots and write to the CSV.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"population of Tokyo, population of New York\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Tokyo Population 2025', 'url': 'https://worldpopulationreview.com/cities/japan/tokyo', 'content': \"Tokyo is, by most measures, the richest city in the world. Its total GDP in 2007 was $1.9 billion; that‚Äôs over $300 million higher than the next richest city, New York. When adjusted for Purchasing Power Parity (PPP) the difference between Tokyo and New York narrows : in 2005 Tokyo had a PPP GDP of $1.617 billion, compared to $1.403 for New York. [...] Tokyo's 2025 population is now estimated at 37,036,200. In 1950, the population of Tokyo was 11,274,600. Tokyo experienced a decrease of -78,800 residents over the past year, marking an annual decline of -0.21%.These population estimates and projections come from the latest revision of the UN World Urbanization Prospects. These estimates represent the Urban agglomeration of Tokyo, which typically includes Tokyo's population in addition to adjacent suburban areas.\\n\\n37M\\n\\nTotal Population [...] A recent study by the Tokyo Metropolitan Government, which included a group of academics and city officials, estimated the population of Tokyo in 2100. The group estimates that Tokyo‚Äôs population will be just 7.13 million, compared to 13.16 million as of the 2010 census. They also predicted the city will peak at 13.35 million in 2020 before a relentless downslide. Meanwhile, Japan‚Äôs population as a whole will decline by over 61% by 2100.\", 'score': 0.63452125}, {'title': 'Demographics of Tokyo', 'url': 'https://en.wikipedia.org/wiki/Demographics_of_Tokyo', 'content': 'The \\\\\\\\demography of Tokyo\\\\\\\\ is analysed by the Tokyo Metropolitan Government and data is produced for each of the Special wards of Tokyo, the Western Tokyo and the Tokyo Islands, and for all of Tokyo prefecture as a whole.( Statistical information is produced about the size and geographical breakdown of the population, the number of people entering and leaving country and the number of people in each demographic subgroup. As of 2025, the total population of Tokyo is 14,195,730 and had the [...] | 2016 | 13,651,276 | 111,964 | 113,415 | ‚Äì1,451 | 8.20 | 8.31 | ‚Äì0.11 | 1.24 |\\n| 2017 | 13,773,187 | 108,990 | 116,453 | ‚Äì7,463 | 7.91 | 8.45 | ‚Äì0.54 | 1.21 |\\n| 2018 | 13,888,986 | 107,150 | 119,253 | ‚Äì12,103 | 7.72 | 8.59 | ‚Äì0.87 | 1.20 |\\n| 2019 | 14,004,097 | 101,818 | 120,870 | ‚Äì19,052 | 7.27 | 8.63 | ‚Äì1.36 | 1.15 |\\n| 2020 | 14,047,594 | 99,661 | 121,219 | ‚Äì21,558 | 7.09 | 8.63 | ‚Äì1.54 | 1.12 |\\n| 2021 | 14,011,487 | 95,404 | 127,649 | ‚Äì32,245 | 6.81 | 9.11 | ‚Äì2.30 | 1.08 | [...] | 2010 | 13,159,388 | 108,135 | 104,238 | 3,897 | 8.22 | 7.92 | 0.30 | 1.12 |\\n| 2011 | 13,191,203 | 106,027 | 105,723 | 304 | 8.04 | 8.01 | 0.03 | 1.06 |\\n| 2012 | 13,225,551 | 107,401 | 109,194 | ‚Äì1,793 | 8.12 | 8.25 | ‚Äì0.14 | 1.09 |\\n| 2013 | 13,301,154 | 109,986 | 110,507 | ‚Äì521 | 8.27 | 8.31 | ‚Äì0.04 | 1.13 |\\n| 2014 | 13,398,087 | 110,629 | 111,024 | ‚Äì395 | 8.26 | 8.28 | ‚Äì0.03 | 1.15 |\\n| 2015 | 13,515,271 | 113,194 | 111,673 | 1,521 | 8.37 | 8.26 | 0.11 | 1.24 |', 'score': 0.47884622}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to extract the populations from the search results.  The results aren't perfectly consistent, so I'll choose the most recent and reliable-looking numbers.  For London, I'll use 9,841,000. For Tokyo, I'll use 37,036,200.  I need to find a reliable population number for New York City.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"population of New York City\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Demographics of New York City - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Demographics_of_New_York_City', 'content': \"New York City is the most populous city in the United States, with an estimated 8,804,190 people living in the city, according to the 2020 U.S. Census (up from 8,175,133 in 2010; 8.0 million in 2000; and 7.3 million in 1990). This amounts to about 44% of New York State's population and a similar percentage of the metropolitan regional population. New York's two key demographic features are its population density and cultural diversity. The city's population density of 29,091.3 people per square [...] New York has ranked first in population among American cities since the first census in 1790. New York will maintain this position for the foreseeable future, although there are varying forecasts on how much the population will increase. The most realistic population projections from the Department of City Planning anticipate a 1.1 million increase by 2030, bringing the city's population total to 9.1 million.[citation needed] [...] New York is the largest city in the United States, with the city proper's population more than double the next largest city, Los Angeles (or roughly equivalent to the combined populations of Los Angeles, Chicago, and Houston, the United States' second, third, and fourth most populous cities respectively). In 2006, demographers estimated New York's population would reach 9.1 million by 2030.\", 'score': 0.9222657}, {'title': 'New York City - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/New_York_City', 'content': 'With an estimated population in July 2024 of 8,478,072, distributed over 300.46 square miles (778.2 km2), the city is the most densely populated major city in the United States. New York City has more than double the population of Los Angeles, the nation\\'s second-most populous city. Over 20.1 million people live in New York City\\'s metropolitan statistical area and 23.5 million in its combined statistical area as of 2020, both largest in the US. New York City is one of the world\\'s most populous [...] | ‚Ä¢ Mayor | Eric Adams (D \"Democratic Party (United States)\")) |\\n| Area  | |\\n| ‚Ä¢ Total | 472.43 sq mi (1,223.59 km2) |\\n| ‚Ä¢ Land | 300.46 sq mi (778.18 km2) |\\n| ‚Ä¢ Water | 171.97 sq mi (445.41 km2) |\\n| Highest elevation  | 401 ft (122 m) |\\n| Lowest elevation | 0 ft (0 m) |\\n| Population (2020) | |\\n| ‚Ä¢ Total | 8,804,190 |\\n| ‚Ä¢ Estimate (2024) | 8,478,072 |\\n| ‚Ä¢ Rank | 1st in the United States |\\n| ‚Ä¢ Density | 29,302.7/sq mi (11,313.8/km2) |\\n| ‚Ä¢ Urban  | 19,426,449 |', 'score': 0.9088853}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought:I'll use the population numbers from the search results: London (9,841,000), Tokyo (37,036,200), and New York City (8,478,072). I'll calculate the square roots, format the data, and write it to the CSV. Then I'll read and display the CSV contents.\n",
      "\n",
      "Action: square_root_tool\n",
      "Action Input: \"9841000\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m3137.036818400447\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought:I'll calculate the square roots for Tokyo and New York City's populations. Then I'll write all the city data to the CSV file.  Finally, I'll read and display the CSV.\n",
      "\n",
      "Action: square_root_tool\n",
      "Action Input: \"37036200\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m6085.737424503295\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: square_root_tool\n",
      "Action Input: \"8478072\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2911.712897934822\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: write_to_csv\n",
      "Action Input: \"London,9841000,3137.036818400447\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mNone\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: write_to_csv\n",
      "Action Input: \"Tokyo,37036200,6085.737424503295\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mNone\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: write_to_csv\n",
      "Action Input: \"New York,8478072,2911.712897934822\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mNone\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: read_from_csv\n",
      "Action Input: \"read\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\"London,9841000,3137.036818400447\"\n",
      "\n",
      "\"Tokyo,37036200,6085.737424503295\"\n",
      "\n",
      "New,\"York,8478072,2911.712897934822\"\n",
      "\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought:I now know the final answer.  The CSV contains some formatting issues (the \"New\" and \"York\" are on separate lines).  However, I'll present the output as it is, noting the formatting problem.\n",
      "\n",
      "Final Answer: The CSV file contains the following data, but there's a formatting issue with the \"New York\" entry:\n",
      "\n",
      "London,9841000,3137.036818400447\n",
      "Tokyo,37036200,6085.737424503295\n",
      "New,\"York,8478072,2911.712897934822\n",
      "\n",
      "The \"New York\" row should read \"New York,8478072,2911.712897934822\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The CSV file contains the following data, but there\\'s a formatting issue with the \"New York\" entry:\\n\\nLondon,9841000,3137.036818400447\\nTokyo,37036200,6085.737424503295\\nNew,\"York,8478072,2911.712897934822\\n\\nThe \"New York\" row should read \"New York,8478072,2911.712897934822\"'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent4 = initialize_agent(\n",
    "    tools = [search, square_root_tool , write_to_csv, read_from_csv],\n",
    "    llm = llm,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "cities = \"London, Tokyo, New York\"\n",
    "agent4.run(f\"You are an agent that will fetch population count of these cities {cities}. After finding the population, find the square root of each city and write it into the csv file in the format city,population,root. Display the final csv file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f420b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm2 = OllamaLLM(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fee588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current president of the United States is. I will use tavily_search_results_json for this task.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"current president of the United States\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'List of presidents of the United States - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States', 'content': 'The first president, George Washington, won a unanimous vote of the Electoral College. The incumbent president is Donald Trump, who assumed office on January 20, 2025. Since the office was established in 1789, 45 men have served in 47 presidencies. The discrepancy is due to the nonconsecutive terms of Grover Cleveland (counted as the 22nd and 24th president) and Trump (counted as the 45th and 47th president). [...] | Presidency timelines |  Washington  J. Adams  McKinley  T. Roosevelt  Taft  Wilson  Harding  Coolidge  Hoover  F. D. Roosevelt  Truman  Eisenhower  Kennedy  L. B. Johnson  Nixon  Ford  Carter  Reagan  G. H. W. Bush  Clinton  G. W. Bush  Obama  Trump  Biden |\\n|  Category  List | | [...] (2009‚Äì2017) 45. Donald Trump (2017‚Äì2021) 46. Joe Biden (2021‚Äì2025) 47. Donald Trump (2025‚Äìpresent) |', 'score': 0.8170061}, {'title': 'The Presidents Timeline - White House Historical Association', 'url': 'https://www.whitehousehistory.org/the-presidents-timeline', 'content': \"George Washington's Epaulets\\nAbraham Lincoln's Cravat\\nSuited to Lead Composite\\nDonald Trump\\nThe Carters with Prime Minister Thatcher in the Center Hall\\nThe Inauguration of John Quincy Adams\\nPresident Truman with Marine Guard During Trip to Key West\\nPostcard of the Harry S. Truman in Uniform\\nPresident Jimmy Carter in Plains, Georgia\\nPresident Roosevelt Delievers a Speech in Waterville, Maine\\nAmbrotype of Abraham Lincoln\\nDetail of President Abraham Lincoln's Coat [...] Featuring John Plashal and Fred Schneider\\n\\n### Queen Elizabeth II and America‚Äôs Presidents\\n\\nFeaturing David Charter\\n\\n### St. John‚Äôs, the Church of the Presidents\\n\\nFeaturing Rev. Robert Fisher, Rector at St. John‚Äôs Church\\n\\n### Blair House: The President‚Äôs Guest House\\n\\nFeaturing The Honorable Capricia Marshall, Ambassador Stuart Holliday, and Matthew Wendel\\n\\n### Presidential Leadership Lessons\\n\\nFeaturing Talmage Boston\\n\\n### The Historic Stephen Decatur House [...] Read Digital Version\\nForeward by William SealeThe Presidents and Baseball: Presidential Openers and Other Traditions by Frederic J. FrommerUlysses S. Grant's White House Billiard Saloon by David RamseyTheodore Roosevelt: The President Who Saved Football by Mary Jo BinkerHoover Ball and Wellness in the White House by Matthew SchaeferCapturing A Moment in Time: Remembering My Summer Photographing President Eisenhower by Al\\n\\n### Road Trip to the Presidents Heads\", 'score': 0.22000751}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The observation suggests that the current president of the United States is Donald Trump, as stated in the Wikipedia article. However, it seems there might be a discrepancy or error in the provided information, as Donald Trump's second term (2025‚Äìpresent) is mentioned, which would be unusual given that his first term ended in 2021. It's important to cross-check this information with other reliable sources to confirm the correct answer.\n",
      "\n",
      "Thought: I should cross-check the information from Wikipedia with another source to ensure its accuracy.\n",
      "\n",
      "Action: tavily_search_results_json\n",
      "Action Input: \"current president of the United States 2025\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'President of the United States', 'url': 'https://en.wikipedia.org/wiki/President_of_the_United_States', 'content': 'In all, 45 individuals have served 47 presidencies spanning 60 four-year terms. Donald Trump is the 47th and current president since January 20, 2025.', 'score': 0.8571119}, {'title': 'President Donald J. Trump - The White House', 'url': 'https://www.whitehouse.gov/administration/donald-j-trump/', 'content': 'Trump. 45th & 47th President of the United States. President Donald J. Trump Official Presidential Portrait. After a landslide election victory in 2024,', 'score': 0.32334858}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m The cross-check with another source confirms that Donald Trump is indeed the current president of the United States as of 2025.\n",
      "\n",
      "Final Answer: Donald Trump is the current president of the United States.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is the current president of the United States',\n",
       " 'output': 'Donald Trump is the current president of the United States.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "\n",
    "agent5 = initialize_agent(\n",
    "    tools = [search],\n",
    "    llm=llm2,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    handle_parsing_error = True\n",
    ")\n",
    "\n",
    "agent5.invoke({\"input\":\"Who is the current president of the United States\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33783936",
   "metadata": {},
   "source": [
    "performing with LM studio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92baba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm3 = ChatOpenAI(\n",
    "    model=\"llama-3.2-1b-instruct\",\n",
    "    openai_api_key = 'lm-studio', # type: ignore\n",
    "    openai_api_base=\"http://localhost:1234/v1\" # type: ignore\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60d42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\" However, I'm a large language model, I don't have real-time access to current information. My training data only goes up until 2021.\\n\\nThat being said, as of my knowledge cutoff in 2021, the President of the United States was Joe Biden. If you're asking about his current status or if there are any changes since then, please let me know and I'll do my best to provide an updated answer!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 16, 'total_tokens': 105, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama-3.2-1b-instruct', 'system_fingerprint': 'llama-3.2-1b-instruct', 'id': 'chatcmpl-5n68h12sg3ga3umbuky935', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--2615e978-b506-4350-9c08-5635a49f58fe-0' usage_metadata={'input_tokens': 16, 'output_tokens': 89, 'total_tokens': 105, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(llm3.invoke(\"Who is the current president of USA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9206c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: ` Question: Who is the current president of the United States\nThought: You should always think about what to do. \nAction Input: Search for the current President of the United States using tavily_search_results_json`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:801\u001b[39m, in \u001b[36mAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    800\u001b[39m full_output = \u001b[38;5;28mself\u001b[39m.llm_chain.predict(callbacks=callbacks, **full_inputs)\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\mrkl\\output_parser.py:80\u001b[39m, in \u001b[36mMRKLOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     79\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[32m     81\u001b[39m         msg,\n\u001b[32m     82\u001b[39m         observation=MISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[32m     83\u001b[39m         llm_output=text,\n\u001b[32m     84\u001b[39m         send_to_llm=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     85\u001b[39m     )\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re.search(\n\u001b[32m     87\u001b[39m     \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*Action\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*Input\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]*(.*)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     88\u001b[39m     text,\n\u001b[32m     89\u001b[39m     re.DOTALL,\n\u001b[32m     90\u001b[39m ):\n",
      "\u001b[31mOutputParserException\u001b[39m: Could not parse LLM output: ` Question: Who is the current president of the United States\nThought: You should always think about what to do. \nAction Input: Search for the current President of the United States using tavily_search_results_json`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m      3\u001b[39m react_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a helpful assistant that uses tools.\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mWhen answering, you must strictly follow this format:\u001b[39m\n\u001b[32m      5\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33mNever add explanations after Action or Action Input.\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     19\u001b[39m agent6 = initialize_agent(\n\u001b[32m     20\u001b[39m     tools = [search],\n\u001b[32m     21\u001b[39m     llm=llm3,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     handle_parsing_error = \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43magent6\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWho is the current president of the United States\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\chains\\base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1326\u001b[39m             \u001b[38;5;28mself\u001b[39m._iter_next_step(\n\u001b[32m   1327\u001b[39m                 name_to_tool_map,\n\u001b[32m   1328\u001b[39m                 color_mapping,\n\u001b[32m   1329\u001b[39m                 inputs,\n\u001b[32m   1330\u001b[39m                 intermediate_steps,\n\u001b[32m   1331\u001b[39m                 run_manager,\n\u001b[32m   1332\u001b[39m             ),\n\u001b[32m   1333\u001b[39m         ),\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langchain_tutorial\\venv\\Lib\\site-packages\\langchain\\agents\\agent.py:1369\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[32m   1363\u001b[39m     msg = (\n\u001b[32m   1364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn output parsing error occurred. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1365\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1367\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1368\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1370\u001b[39m text = \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: ` Question: Who is the current president of the United States\nThought: You should always think about what to do. \nAction Input: Search for the current President of the United States using tavily_search_results_json`\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "react_prompt = \"\"\"You are a helpful assistant that uses tools.\n",
    "When answering, you must strictly follow this format:\n",
    "\n",
    "Question: the input question to answer\n",
    "Thought: your reasoning about what to do\n",
    "Action: the exact name of the tool to use, nothing else\n",
    "Action Input: the input to the tool, in plain text\n",
    "\n",
    "If you already have the answer, respond like this:\n",
    "\n",
    "Thought: I know the answer\n",
    "Final Answer: <the answer>\n",
    "\n",
    "Never add explanations after Action or Action Input.\n",
    "\"\"\"\n",
    "\n",
    "agent6 = initialize_agent(\n",
    "    tools = [search],\n",
    "    llm=llm3,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    handle_parsing_error = True, \n",
    ")\n",
    "\n",
    "agent6.invoke({\"input\":\"Who is the current president of the United States\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b8881",
   "metadata": {},
   "source": [
    "## 4.6 Agent Types\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# üß† LangChain Agent Types\n",
    "\n",
    "LangChain provides different **agent types**, each with its own reasoning style, memory handling, and tool support. Agents differ in **how they decide when and how to use tools**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Zero-Shot ReAct Description\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Uses the **ReAct (Reason + Act)** framework.\n",
    "* LLM decides which tool to call based only on tool descriptions.\n",
    "* No prior examples (‚Äúzero-shot‚Äù).\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* General-purpose agents.\n",
    "* Tasks where the model needs to reason step by step and use tools.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Supports only **single-input tools** (`str -> str`).\n",
    "* No memory between calls.\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Conversational ReAct Description\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Same as Zero-Shot ReAct, but includes **memory** of the conversation.\n",
    "* Lets you ask follow-up questions without repeating context.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* Chatbots and assistants that need dialogue memory.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Still only works with **single-input tools**.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Self-Ask with Search\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Agent decomposes a query into **sub-questions**.\n",
    "* Uses **search tools** when it cannot answer from reasoning alone.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* Knowledge Q\\&A.\n",
    "* Tasks where an LLM must fetch external information.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Not general-purpose ‚Äî designed specifically for search-based reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Plan-and-Execute\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Works in **two stages**:\n",
    "\n",
    "  1. LLM **plans** the full set of steps.\n",
    "  2. Then **executes** each step with sub-agents.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* Complex, multi-step workflows.\n",
    "* Scenarios requiring structured execution instead of ad-hoc reasoning.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Can be slower (planning + execution).\n",
    "* Sometimes ‚Äúover-plans.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Structured Chat Agent\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Unlike Zero-Shot, it supports **multi-input tools**.\n",
    "* LLM calls tools with structured arguments (like a JSON dict).\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* When tools need multiple parameters (e.g., `{city: \"Tokyo\", population: 125000000}`).\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Requires stricter prompts and well-defined tool schemas.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Functions Agent (OpenAI/Gemini)\n",
    "\n",
    "**Description**\n",
    "\n",
    "* Uses **function-calling APIs** of LLMs (OpenAI, Gemini, etc.).\n",
    "* LLM outputs valid JSON with function arguments.\n",
    "* Very reliable for tool use.\n",
    "\n",
    "**When to Use**\n",
    "\n",
    "* If your LLM supports function calling (e.g., GPT-4, Gemini).\n",
    "* Production-grade tool invocation.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Dependent on LLM providers that implement function calling.\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Summary Table\n",
    "\n",
    "| Agent Type                      | Multi-Input Tools? | Memory? | Best For                  |\n",
    "| ------------------------------- | ------------------ | ------- | ------------------------- |\n",
    "| Zero-Shot ReAct Description     | ‚ùå No               | ‚ùå No    | General tool use          |\n",
    "| Conversational ReAct            | ‚ùå No               | ‚úÖ Yes   | Chat assistants           |\n",
    "| Self-Ask with Search            | ‚ùå No               | ‚ùå No    | Knowledge Q\\&A            |\n",
    "| Plan-and-Execute                | ‚ùå No               | ‚ùå No    | Complex workflows         |\n",
    "| Structured Chat Agent           | ‚úÖ Yes              | ‚ùå No    | Multi-input tools         |\n",
    "| Functions Agent (OpenAI/Gemini) | ‚úÖ Yes              | ‚ùå No    | Reliable structured calls |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö° **Tip**: Start with **Zero-Shot ReAct** (simplest), then move to **Structured Chat** or **Functions Agent** once your tools get more complex.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
