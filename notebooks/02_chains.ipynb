{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93822f52",
   "metadata": {},
   "source": [
    "# Chapter 2: Working with Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fd95f",
   "metadata": {},
   "source": [
    "Goals:\n",
    "- Understand LLMChain (prompt → LLM → output)\n",
    "- Use multiple variables in prompts\n",
    "- Build simple sequential two-step flows\n",
    "- See how to name outputs (SequentialChain)\n",
    "- Use `verbose=True` to inspect prompts & intermediate outputs\n",
    "\n",
    "Assumes: you already completed `01_intro` and have your `.env` with `GOOGLE_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90f4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the api keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "google_key = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f14edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='models/gemini-1.5-flash' google_api_key=SecretStr('**********') temperature=0.5 client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001CDDE939190> default_metadata=() model_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import LLMChain , SimpleSequentialChain, SequentialChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# initialize the LLM\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-flash\",\n",
    "    api_key = google_key,\n",
    "    temperature = 0.5\n",
    ")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38676d8",
   "metadata": {},
   "source": [
    "## 2.1 Recap: Single LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d237d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amalv\\AppData\\Local\\Temp\\ipykernel_1052\\1882250279.py:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain1 = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few suggestions, playing with different styles:\n",
      "\n",
      "**Traditional & Geographic:**\n",
      "\n",
      "* **Ashford Town FC:** (If based near Ashford)  Simple, classic.\n",
      "* **The Severnside Rovers:** (If near the River Severn) Evokes a sense of place and movement.\n",
      "* **North Downs United:** (If near the North Downs)  Geographic and suggests unity.\n",
      "* **Wessex Wanderers:** (If in the Wessex region)  Historical and adventurous.\n",
      "\n",
      "\n",
      "**Modern & Catchy:**\n",
      "\n",
      "* **City Phoenix FC:** Modern, suggests rebirth or rising from the ashes.\n",
      "* **Steel City United:** (If in a steel-producing area)  Strong, industrial feel.\n",
      "* **The Albion Eagles:**  Combines a classic feel with a powerful image.\n",
      "* **Vanguard FC:**  Modern, suggests forward-thinking and ambition.\n",
      "\n",
      "\n",
      "**Unique & Quirky:**\n",
      "\n",
      "* **The Clockwork Crows:**  Unusual and memorable.\n",
      "* **The Crimson Tide FC:**  Evocative and memorable.\n",
      "* **The Ironclad Rovers:**  Strong and adventurous.\n",
      "\n",
      "\n",
      "Remember to check if the name is already in use by another club before settling on one.  You can also combine elements from different suggestions to create something unique.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Suggest a name for a {sport} club based in {country}.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "output = chain1.invoke({\n",
    "    \"sport\":\"football\",\n",
    "    \"country\":\"England\"\n",
    "})\n",
    "\n",
    "print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb35c4",
   "metadata": {},
   "source": [
    "## 2.2 SimpleSequenceChain\n",
    "- Used when chain 1 produces a single output which can be used as input for next chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6ebf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mTotal internal reflection occurs when light traveling from a denser medium to a less dense medium strikes the interface at an angle greater than the critical angle, causing all the light to be reflected back into the denser medium.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mFiber optic cables.  Total internal reflection is the fundamental principle allowing light signals to travel long distances down a fiber optic cable with minimal loss.  The light is continuously reflected internally within the core of the fiber, preventing it from escaping.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Total Internal Reflection', 'output': 'Fiber optic cables.  Total internal reflection is the fundamental principle allowing light signals to travel long distances down a fiber optic cable with minimal loss.  The light is continuously reflected internally within the core of the fiber, preventing it from escaping.'}\n"
     ]
    }
   ],
   "source": [
    "prompt_a = PromptTemplate.from_template(\"Describe a {concept} in 1 sentence.\")\n",
    "chain1 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_a\n",
    ")\n",
    "# chain B uses output from chain1\n",
    "prompt_b = PromptTemplate.from_template(\"Suggest one practical use for this: \\n\\n{input}\")\n",
    "chain2 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt_b\n",
    ")\n",
    "\n",
    "#Turn it into a simple sequential chain\n",
    "seq = SimpleSequentialChain(\n",
    "    chains = [chain1 , chain2],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "print(seq.invoke(\"Total Internal Reflection\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896c114",
   "metadata": {},
   "source": [
    "## 2.3 SequentialChain with named variables\n",
    "\n",
    "* output_key on each LLMChain assigns the chain's output into a named key in the overall state.\n",
    "* SequentialChain lets you explicitly define which top-level inputs are required and which outputs you want back.\n",
    "* The result is typically a dict with keys listed in output_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceac5926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'language': 'java', 'concept_info': \"It's a general-purpose, class-based, object-oriented programming language that's widely used for developing applications on various platforms.\", 'result': \"That description points to **many object-oriented programming languages**, not a single specific technology.  Many languages fit that description, including (but not limited to):\\n\\n* **Java:**  A very popular choice fitting the description perfectly.\\n* **C#:**  Another widely used language, especially in Microsoft environments.\\n* **Python:** While often used in a more dynamic style, Python also supports object-oriented programming and is general-purpose.\\n* **C++:** A powerful language that's class-based and object-oriented, though it also allows procedural programming.\\n* **PHP:** Though often associated with web development, PHP is also a general-purpose, class-based, object-oriented language.\\n\\n\\nTo know the *specific* technology, you'd need more information about the application or system it's used in.\"}\n"
     ]
    }
   ],
   "source": [
    "#chain 1\n",
    "prompt1 = PromptTemplate.from_template(\"Desribe this language {language} in one sentance. You must not use the word {language} in the result\")\n",
    "chain1 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt1,\n",
    "    output_key = \"concept_info\"\n",
    "    )\n",
    "\n",
    "\n",
    "#chain 2\n",
    "prompt2 =PromptTemplate.from_template(\"What is the technology used in this \\n {concept_info}.\")\n",
    "chain2 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt2,\n",
    "    output_key = \"result\"\n",
    ")\n",
    "\n",
    "# Sequential chain\n",
    "\n",
    "seq_chain = SequentialChain(\n",
    "    chains = [chain1 , chain2],\n",
    "    input_variables = [\"language\"],\n",
    "    output_variables = [\"concept_info\" , \"result\"],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "result = seq_chain.invoke({\"language\": \"java\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3435dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That description points to **many object-oriented programming languages**, not a single specific technology.  Many languages fit that description, including (but not limited to):\n",
      "\n",
      "* **Java:**  A very popular choice fitting the description perfectly.\n",
      "* **C#:**  Another widely used language, especially in Microsoft environments.\n",
      "* **Python:** While often used in a more dynamic style, Python also supports object-oriented programming and is general-purpose.\n",
      "* **C++:** A powerful language that's class-based and object-oriented, though it also allows procedural programming.\n",
      "* **PHP:** Though often associated with web development, PHP is also a general-purpose, class-based, object-oriented language.\n",
      "\n",
      "\n",
      "To know the *specific* technology, you'd need more information about the application or system it's used in.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6bf28",
   "metadata": {},
   "source": [
    "## 2.4 Inspecting the built prompt\n",
    "format() renders the prompt template locally — useful for checking variable names & formatting before a remote API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713b24c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered prompt text:\n",
      "Describe an island made of glass in one line.\n"
     ]
    }
   ],
   "source": [
    "# If you want to see the final prompt BEFORE calling the LLM:\n",
    "pt = PromptTemplate.from_template(\"Describe {thing} in one line.\")\n",
    "print(\"Rendered prompt text:\")\n",
    "print(pt.format(thing=\"an island made of glass\"))   # show the filled string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd695edd",
   "metadata": {},
   "source": [
    "## 2.4 Practice tasks\n",
    "\n",
    "A) Multi-variable prompt:\n",
    "   - Prompt: \"Write a menu item name and a 1-line description for a {cuisine} dish with {main_ingredient}.\"\n",
    "   - Use LLMChain and test with 3 cuisines.\n",
    "\n",
    "B) Two-step pipeline:\n",
    "   - Chain 1: Given {genre}, write a short plot (2–3 sentences).\n",
    "   - Chain 2: Given the plot, produce 3 taglines.\n",
    "   - Use SequentialChain, set output_keys, run with verbose=True.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55fa05",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d915ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Name:**  Coastal Curry Catch\n",
      "\n",
      "**Description:**  Succulent seafood simmered in a vibrant coconut-tomato curry with fragrant spices.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"Write a menu item name and a 1-line description for a {cusine} dish with {main_ingredient}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "print(chain.invoke({\"cusine\":\"Indian\" , \"main_ingredient\": \"sea food\"})[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01638ca",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795d0780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "1. **The fog hides more than just the island. It hides the truth.** (Focuses on mystery and suspense)\n",
      "2. **Their smiles are perfect. Their secret is terrifying.** (Highlights the deceptive nature of the creatures and the horror)\n",
      "3. **Memory is his only weapon.  Survival is his only hope.** (Emphasizes the protagonist's struggle and the high stakes)\n"
     ]
    }
   ],
   "source": [
    "prompt1 = PromptTemplate.from_template(\"Given {genre}, write a short plot (2-3 sentences).\")\n",
    "chain1 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt1,\n",
    "    output_key=\"plot\"\n",
    ")\n",
    "prompt2 = PromptTemplate.from_template(\"Produce three taglines using this plot:\\n{plot}\")\n",
    "chain2 = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt2,\n",
    "    output_key = \"result\"\n",
    ")\n",
    "\n",
    "seq = SequentialChain(\n",
    "    chains = [chain1, chain2],\n",
    "    input_variables = [\"genre\"],\n",
    "    output_variables = [\"plot\" , \"result\"],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "output = seq.invoke({\"genre\":\"horror\"})\n",
    "print(output[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
